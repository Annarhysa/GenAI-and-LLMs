{"cells":[{"cell_type":"markdown","metadata":{"id":"HTYTRlgEInNS"},"source":["# Poem Generation using FastAI\n"]},{"cell_type":"markdown","metadata":{"id":"mM0YJ6eu6Vkk"},"source":["In this tutorial you will see how to fine-tune a pretrained transformer model from the transformers library by HuggingFace. It can be very simple with FastAI's data loaders. It's possible to use any of the pretrained models from HuggingFace. Below we will experiment with GPT2. "]},{"cell_type":"markdown","metadata":{"id":"-FVVxuGPI2-e"},"source":["## Import Libraries\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-14T03:15:41.765172Z","iopub.status.busy":"2023-10-14T03:15:41.764889Z","iopub.status.idle":"2023-10-14T03:15:41.769948Z","shell.execute_reply":"2023-10-14T03:15:41.768672Z","shell.execute_reply.started":"2023-10-14T03:15:41.765146Z"},"id":"Jd51B8ZYIaky","trusted":true},"outputs":[],"source":["# from fastbook import *\n","from fastai.text.all import *\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-14T03:15:43.685246Z","iopub.status.busy":"2023-10-14T03:15:43.684970Z","iopub.status.idle":"2023-10-14T03:16:07.709927Z","shell.execute_reply":"2023-10-14T03:16:07.708559Z","shell.execute_reply.started":"2023-10-14T03:15:43.685219Z"},"id":"alC0xd-aNjKF","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aef38c5b527e4e53859ac14c9126a0ef","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\annar\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae3178c882c540a09679bd294b159968","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["pretrained_weights = 'gpt2'\n","tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n","model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"]},{"cell_type":"markdown","metadata":{"id":"-VxqkIvvJ9gv"},"source":["## Read Data\n","This data is organized by folder. There are two main folders: forms (e.g. haiku, sonnet, etc.) and topics (e.g. love, peace, etc.). Those main folders contain subfolders for the subcategories and then the poem txt files are contained in those.\n","With fastai, it's quite easy to read the data with the the get_text_files function. You can select all folders or select specific ones."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:12:56.916695Z","iopub.status.busy":"2023-10-13T02:12:56.91625Z","iopub.status.idle":"2023-10-13T02:12:56.921411Z","shell.execute_reply":"2023-10-13T02:12:56.92042Z","shell.execute_reply.started":"2023-10-13T02:12:56.916656Z"},"id":"8CIpgsfMQPfu","trusted":true},"outputs":[],"source":["path = '../input/poemsdataset'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:13:00.870092Z","iopub.status.busy":"2023-10-13T02:13:00.8697Z","iopub.status.idle":"2023-10-13T02:13:05.318956Z","shell.execute_reply":"2023-10-13T02:13:05.317971Z","shell.execute_reply.started":"2023-10-13T02:13:00.870061Z"},"id":"rOZu9LCfMVPZ","outputId":"9b6be92a-14cd-40e6-e0f6-720ff9c92774","trusted":true},"outputs":[],"source":["poems = get_text_files(path, folders = ['forms','topics'])\n","print(\"There are\",len(poems),\"poems in the dataset\")"]},{"cell_type":"markdown","metadata":{"id":"u9REr2f9676E"},"source":["We'll start off with training the model on ballads. There are only 100 ballads so it won't take as long to train. However you can add more poem forms. For instance, a haiku would be very cool to experiment with and to see if it maintains the 5,7,5 syllable structure. You can also change the path to the topics folder instead of poem forms and you can try out a bunch of poem topics like love, anger, depression, etc.. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:13:09.611448Z","iopub.status.busy":"2023-10-13T02:13:09.607921Z","iopub.status.idle":"2023-10-13T02:13:09.626533Z","shell.execute_reply":"2023-10-13T02:13:09.625526Z","shell.execute_reply.started":"2023-10-13T02:13:09.611392Z"},"id":"D6HsJQLtJ9P2","outputId":"c91cf59c-5e5f-4248-9aac-1dbe2ae6ab08","trusted":true},"outputs":[],"source":["ballads = get_text_files(path+'/forms', folders = ['ballad'])\n","print(\"There are\",len(ballads),\"ballads in the dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:14:53.691252Z","iopub.status.busy":"2023-10-13T02:14:53.690941Z","iopub.status.idle":"2023-10-13T02:14:53.700261Z","shell.execute_reply":"2023-10-13T02:14:53.699406Z","shell.execute_reply.started":"2023-10-13T02:14:53.691226Z"},"id":"aff_yTWDMlkm","outputId":"d59f2fff-0c13-40dc-bf09-97881ee40987","trusted":true},"outputs":[],"source":["txt = poems[0].open().read(); #read the first file\n","print(txt)"]},{"cell_type":"markdown","metadata":{"id":"AAiN7YVH8HwX"},"source":["## Prepare the Data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:14:58.71969Z","iopub.status.busy":"2023-10-13T02:14:58.719391Z","iopub.status.idle":"2023-10-13T02:14:58.748726Z","shell.execute_reply":"2023-10-13T02:14:58.747115Z","shell.execute_reply.started":"2023-10-13T02:14:58.719662Z"},"id":"b2-JJ8BGIgMU","trusted":true},"outputs":[],"source":["ballads = L(o.open().read() for o in ballads) # to make things easy we will gather all texts in one numpy array"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:02.808011Z","iopub.status.busy":"2023-10-13T02:15:02.805235Z","iopub.status.idle":"2023-10-13T02:15:02.815542Z","shell.execute_reply":"2023-10-13T02:15:02.814392Z","shell.execute_reply.started":"2023-10-13T02:15:02.807968Z"},"id":"Lu4ek-rIIn84","trusted":true},"outputs":[],"source":["def flatten(A):\n","    rt = []\n","    for i in A:\n","        if isinstance(i,list): rt.extend(flatten(i))\n","        else: rt.append(i)\n","    return rt\n","  \n","all_ballads = flatten(ballads)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:06.08493Z","iopub.status.busy":"2023-10-13T02:15:06.084615Z","iopub.status.idle":"2023-10-13T02:15:06.090255Z","shell.execute_reply":"2023-10-13T02:15:06.089169Z","shell.execute_reply.started":"2023-10-13T02:15:06.084901Z"},"id":"XHPQpvvbabmj","trusted":true},"outputs":[],"source":["class TransformersTokenizer(Transform):\n","    def __init__(self, tokenizer): self.tokenizer = tokenizer\n","    def encodes(self, x): \n","        toks = self.tokenizer.tokenize(x)\n","        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n","    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:07.437941Z","iopub.status.busy":"2023-10-13T02:15:07.437614Z","iopub.status.idle":"2023-10-13T02:15:07.445489Z","shell.execute_reply":"2023-10-13T02:15:07.444403Z","shell.execute_reply.started":"2023-10-13T02:15:07.437911Z"},"id":"KEdmTZR7NG5E","trusted":true},"outputs":[],"source":["splits = [range_of(70), range(100)] # use a 70/30 split\n","tls = TfmdLists(all_ballads, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:15.814059Z","iopub.status.busy":"2023-10-13T02:15:15.813702Z","iopub.status.idle":"2023-10-13T02:15:20.51105Z","shell.execute_reply":"2023-10-13T02:15:20.510122Z","shell.execute_reply.started":"2023-10-13T02:15:15.814029Z"},"id":"0O-QWa9LN1IK","outputId":"7aecbf08-6d2e-4016-c2b5-d124d4e94329","trusted":true},"outputs":[],"source":["show_at(tls.train, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:32.912964Z","iopub.status.busy":"2023-10-13T02:15:32.912627Z","iopub.status.idle":"2023-10-13T02:15:39.445044Z","shell.execute_reply":"2023-10-13T02:15:39.444287Z","shell.execute_reply.started":"2023-10-13T02:15:32.912933Z"},"id":"Fv2mSN4LOHob","trusted":true},"outputs":[],"source":["bs,sl = 4,256\n","dls = tls.dataloaders(bs=bs, seq_len=sl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:43.485559Z","iopub.status.busy":"2023-10-13T02:15:43.485259Z","iopub.status.idle":"2023-10-13T02:15:43.610728Z","shell.execute_reply":"2023-10-13T02:15:43.609829Z","shell.execute_reply.started":"2023-10-13T02:15:43.485532Z"},"id":"xpbniW8mOT_g","outputId":"83aaae79-c35d-4192-920e-8e62869e01ec","trusted":true},"outputs":[],"source":["dls.show_batch(max_n=2)"]},{"cell_type":"markdown","metadata":{"id":"kMFnNw748QhY"},"source":["## Fine-tuning the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:49.271231Z","iopub.status.busy":"2023-10-13T02:15:49.270918Z","iopub.status.idle":"2023-10-13T02:15:49.275094Z","shell.execute_reply":"2023-10-13T02:15:49.274193Z","shell.execute_reply.started":"2023-10-13T02:15:49.271205Z"},"id":"jkJCLFncOcqV","trusted":true},"outputs":[],"source":["class DropOutput(Callback):\n","    def after_pred(self): self.learn.pred = self.pred[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:51.911967Z","iopub.status.busy":"2023-10-13T02:15:51.911635Z","iopub.status.idle":"2023-10-13T02:15:51.918041Z","shell.execute_reply":"2023-10-13T02:15:51.917007Z","shell.execute_reply.started":"2023-10-13T02:15:51.911935Z"},"id":"669gGIAuOeJ8","trusted":true},"outputs":[],"source":["learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:16:19.575784Z","iopub.status.busy":"2023-10-13T02:16:19.575487Z","iopub.status.idle":"2023-10-13T02:16:35.568428Z","shell.execute_reply":"2023-10-13T02:16:35.56752Z","shell.execute_reply.started":"2023-10-13T02:16:19.575755Z"},"id":"Z7ZPcyW8Oh0_","outputId":"ef19c779-2e66-41c4-cad8-e908400c1752","trusted":true},"outputs":[],"source":["learn.validate()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:16:41.988836Z","iopub.status.busy":"2023-10-13T02:16:41.988528Z","iopub.status.idle":"2023-10-13T02:17:14.710775Z","shell.execute_reply":"2023-10-13T02:17:14.709945Z","shell.execute_reply.started":"2023-10-13T02:16:41.988809Z"},"id":"ykYFFlCBOnqp","outputId":"27dae545-3669-4386-d399-76a8da0f964f","trusted":true},"outputs":[],"source":["learn.lr_find()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:17:26.630142Z","iopub.status.busy":"2023-10-13T02:17:26.629781Z","iopub.status.idle":"2023-10-13T02:18:04.239768Z","shell.execute_reply":"2023-10-13T02:18:04.238912Z","shell.execute_reply.started":"2023-10-13T02:17:26.630108Z"},"id":"PKySv6QiOvom","outputId":"ac533474-0ec1-4ddd-910c-c47e93098c96","trusted":true},"outputs":[],"source":["learn.fit_one_cycle(1, 1e-4)"]},{"cell_type":"markdown","metadata":{"id":"fdLpyolz8bV7"},"source":["## Poem Generation Example"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:18:15.739804Z","iopub.status.busy":"2023-10-13T02:18:15.739493Z","iopub.status.idle":"2023-10-13T02:18:15.746675Z","shell.execute_reply":"2023-10-13T02:18:15.745495Z","shell.execute_reply.started":"2023-10-13T02:18:15.739768Z"},"id":"D0zOA5wXPDEv","outputId":"27f4d6c1-e3af-4416-99cc-a071130a81c7","trusted":true},"outputs":[],"source":["prompt = 'love is ridiculous' # create an initial text prompt to start your generated text\n","prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","inp.shape"]},{"cell_type":"markdown","metadata":{"id":"_ONkBFg482US"},"source":["Adding the `num_beams` and `no_repeat_ngram_size` arguments make a huge difference. This can be explained [here](https://huggingface.co/blog/how-to-generate). Basically beam search reduces the risk of missing hidden high probability word sequences by keeping the most likely num_beams of hypotheses at each time step and eventually choosing the hypothesis that has the overall highest probability. Without beam search you will obtain a more greedy search. Beam search will always find an output sequence with higher probability than greedy search, but is not guaranteed to find the most likely output. Moreover, without the `no_repeat_ngram_size` you will likely obtain a repeated output. Thus we add a penalty that makes sure that no n-gram appears twice by manually setting the probability of next words that could create an already seen n-gram to 0."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:18:35.882744Z","iopub.status.busy":"2023-10-13T02:18:35.882433Z","iopub.status.idle":"2023-10-13T02:18:36.745433Z","shell.execute_reply":"2023-10-13T02:18:36.744486Z","shell.execute_reply.started":"2023-10-13T02:18:35.882715Z"},"id":"V39qs4aX4_3B","outputId":"31c2beac-22e8-4989-8826-fc50125b80e5","trusted":true},"outputs":[],"source":["preds = learn.model.generate(inp, max_length=60, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(preds[0].cpu().numpy(), skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:18:51.246072Z","iopub.status.busy":"2023-10-13T02:18:51.245715Z","iopub.status.idle":"2023-10-13T02:18:52.070553Z","shell.execute_reply":"2023-10-13T02:18:52.069651Z","shell.execute_reply.started":"2023-10-13T02:18:51.246042Z"},"id":"gEeoQrHrPb8c","outputId":"9d54d66a-654d-40c5-d87a-c9774e2c4ce0","trusted":true},"outputs":[],"source":["prompt = \"I don't know what I would do\"\n","prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","preds = learn.model.generate(inp, max_length=60, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(preds[0].cpu().numpy(), skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
