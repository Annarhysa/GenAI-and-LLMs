{"cells":[{"cell_type":"markdown","metadata":{"id":"HTYTRlgEInNS"},"source":["# Poem Generation using FastAI\n"]},{"cell_type":"markdown","metadata":{"id":"mM0YJ6eu6Vkk"},"source":["In this tutorial you will see how to fine-tune a pretrained transformer model from the transformers library by HuggingFace. It can be very simple with FastAI's data loaders. It's possible to use any of the pretrained models from HuggingFace. Below we will experiment with GPT2. "]},{"cell_type":"markdown","metadata":{"id":"-FVVxuGPI2-e"},"source":["## Import Libraries\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-14T03:15:41.765172Z","iopub.status.busy":"2023-10-14T03:15:41.764889Z","iopub.status.idle":"2023-10-14T03:15:41.769948Z","shell.execute_reply":"2023-10-14T03:15:41.768672Z","shell.execute_reply.started":"2023-10-14T03:15:41.765146Z"},"id":"Jd51B8ZYIaky","trusted":true},"outputs":[],"source":["# from fastbook import *\n","from fastai.text.all import *\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-14T03:15:43.685246Z","iopub.status.busy":"2023-10-14T03:15:43.684970Z","iopub.status.idle":"2023-10-14T03:16:07.709927Z","shell.execute_reply":"2023-10-14T03:16:07.708559Z","shell.execute_reply.started":"2023-10-14T03:15:43.685219Z"},"id":"alC0xd-aNjKF","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aef38c5b527e4e53859ac14c9126a0ef","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\annar\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae3178c882c540a09679bd294b159968","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["pretrained_weights = 'gpt2'\n","tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n","model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"]},{"cell_type":"markdown","metadata":{"id":"-VxqkIvvJ9gv"},"source":["## Read Data\n","This data is organized by folder. There are two main folders: forms (e.g. haiku, sonnet, etc.) and topics (e.g. love, peace, etc.). Those main folders contain subfolders for the subcategories and then the poem txt files are contained in those.\n","With fastai, it's quite easy to read the data with the the get_text_files function. You can select all folders or select specific ones."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:12:56.916695Z","iopub.status.busy":"2023-10-13T02:12:56.91625Z","iopub.status.idle":"2023-10-13T02:12:56.921411Z","shell.execute_reply":"2023-10-13T02:12:56.92042Z","shell.execute_reply.started":"2023-10-13T02:12:56.916656Z"},"id":"8CIpgsfMQPfu","trusted":true},"outputs":[],"source":["path = './data'"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:13:00.870092Z","iopub.status.busy":"2023-10-13T02:13:00.8697Z","iopub.status.idle":"2023-10-13T02:13:05.318956Z","shell.execute_reply":"2023-10-13T02:13:05.317971Z","shell.execute_reply.started":"2023-10-13T02:13:00.870061Z"},"id":"rOZu9LCfMVPZ","outputId":"9b6be92a-14cd-40e6-e0f6-720ff9c92774","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 20657 poems in the dataset\n"]}],"source":["poems = get_text_files(path, folders = ['forms','topics'])\n","print(\"There are\",len(poems),\"poems in the dataset\")"]},{"cell_type":"markdown","metadata":{"id":"u9REr2f9676E"},"source":["We'll start off with training the model on ballads. There are only 100 ballads so it won't take as long to train. However you can add more poem forms. For instance, a haiku would be very cool to experiment with and to see if it maintains the 5,7,5 syllable structure. You can also change the path to the topics folder instead of poem forms and you can try out a bunch of poem topics like love, anger, depression, etc.. "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:13:09.611448Z","iopub.status.busy":"2023-10-13T02:13:09.607921Z","iopub.status.idle":"2023-10-13T02:13:09.626533Z","shell.execute_reply":"2023-10-13T02:13:09.625526Z","shell.execute_reply.started":"2023-10-13T02:13:09.611392Z"},"id":"D6HsJQLtJ9P2","outputId":"c91cf59c-5e5f-4248-9aac-1dbe2ae6ab08","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 100 ballads in the dataset\n"]}],"source":["ballads = get_text_files(path+'/forms', folders = ['ballad'])\n","print(\"There are\",len(ballads),\"ballads in the dataset\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:14:53.691252Z","iopub.status.busy":"2023-10-13T02:14:53.690941Z","iopub.status.idle":"2023-10-13T02:14:53.700261Z","shell.execute_reply":"2023-10-13T02:14:53.699406Z","shell.execute_reply.started":"2023-10-13T02:14:53.691226Z"},"id":"aff_yTWDMlkm","outputId":"d59f2fff-0c13-40dc-bf09-97881ee40987","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2 ABC of H.k. and China revised vision.\n","Barrels tears are wines and salts.\n","With a whisk on goody tails!\n","Wiggle maces to fix the heads.\n","Heads in jack on boxes are ceased.\n","Cry to paranoid truly bosses.\n","Bosses are jokers take your boys.\n","Studs are bogs with fire apples.\n","True predicates worth cases.â€™\n","Descents wash in badly bands.\n","Wholly sales are smart with cats.\n","Who got tenth honors in China?\n","Homage grand to play and plays!\n","Trim the times of hearts then cry.\n","Tanks in steels but voice wail.\n","Bossy dragged by tails that whisked.\n","Go very timid and love the wise.\n","Hands are lent but laws are ends.\n","Cases on courts are borrowed lands.\n","Length long with treads to retch!\n","Straps on times and watch here.\n","Arrays tanks but all are men.\n","Cross all suctions steal the ends.\n","Cave on minds are cages on objects.\n","Rouser rockets powers holes.\n","Confine curses to stop our wounds.\n","Whirl your bodies and jump on grounds.\n","Crouch of soldiers after kicks with flings.\n","Block one leg and hit the middle.\n","Cauchy3 know the tricks to kill.\n","Threaten weak oppressed ill.\n","Surpass scores are bad in honors.\n","Wash to think that build the homes.\n","Angel sins but cauchy3 has funs.\n","Make ones tools when hats are found.\n","Worlds are drawers on bottom noses.\n","Singular ugly piece is rose.\n","Wily mores are teeth of sharks.\n","Saw with tooth is laws in arts.\n","Artful men power with grids.\n","Bodies stamped and wills are ridden.\n","Sign in forth with battles conquered.\n","Triumphs on candles whip the stands.\n","Soups are soaps and faiths not come.\n","We are meats in balls and rice to constants.\n","---Cheung Shun Sang=Cauchy3---\n"]}],"source":["txt = poems[0].open().read(); #read the first file\n","print(txt)"]},{"cell_type":"markdown","metadata":{"id":"AAiN7YVH8HwX"},"source":["## Prepare the Data\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:14:58.71969Z","iopub.status.busy":"2023-10-13T02:14:58.719391Z","iopub.status.idle":"2023-10-13T02:14:58.748726Z","shell.execute_reply":"2023-10-13T02:14:58.747115Z","shell.execute_reply.started":"2023-10-13T02:14:58.719662Z"},"id":"b2-JJ8BGIgMU","trusted":true},"outputs":[{"ename":"UnicodeDecodeError","evalue":"'charmap' codec can't decode byte 0x9d in position 609: character maps to <undefined>","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[1;32mc:\\Users\\annar\\OneDrive\\Desktop\\Visual Studio\\GitHub\\Projects2\\GenAI-and-LLMs\\poem-generation-with-transformers.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/annar/OneDrive/Desktop/Visual%20Studio/GitHub/Projects2/GenAI-and-LLMs/poem-generation-with-transformers.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ballads \u001b[39m=\u001b[39m L(o\u001b[39m.\u001b[39;49mopen()\u001b[39m.\u001b[39;49mread() \u001b[39mfor\u001b[39;49;00m o \u001b[39min\u001b[39;49;00m ballads) \u001b[39m# to make things easy we will gather all texts in one numpy array\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[1;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mcls\u001b[39m): \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\foundation.py:106\u001b[0m, in \u001b[0;36mL.__init__\u001b[1;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, items\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39mrest, use_list\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, match\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m (use_list \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_array(items):\n\u001b[1;32m--> 106\u001b[0m         items \u001b[39m=\u001b[39m listify(items, \u001b[39m*\u001b[39;49mrest, use_list\u001b[39m=\u001b[39;49muse_list, match\u001b[39m=\u001b[39;49mmatch)\n\u001b[0;32m    107\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(items)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\basics.py:66\u001b[0m, in \u001b[0;36mlistify\u001b[1;34m(o, use_list, match, *rest)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mlist\u001b[39m): res \u001b[39m=\u001b[39m o\n\u001b[0;32m     65\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m is_array(o): res \u001b[39m=\u001b[39m [o]\n\u001b[1;32m---> 66\u001b[0m \u001b[39melif\u001b[39;00m is_iter(o): res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(o)\n\u001b[0;32m     67\u001b[0m \u001b[39melse\u001b[39;00m: res \u001b[39m=\u001b[39m [o]\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m match \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;32mc:\\Users\\annar\\OneDrive\\Desktop\\Visual Studio\\GitHub\\Projects2\\GenAI-and-LLMs\\poem-generation-with-transformers.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/annar/OneDrive/Desktop/Visual%20Studio/GitHub/Projects2/GenAI-and-LLMs/poem-generation-with-transformers.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ballads \u001b[39m=\u001b[39m L(o\u001b[39m.\u001b[39mopen()\u001b[39m.\u001b[39mread() \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m ballads) \u001b[39m# to make things easy we will gather all texts in one numpy array\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mcharmap_decode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,decoding_table)[\u001b[39m0\u001b[39m]\n","\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 609: character maps to <undefined>"]}],"source":["ballads = L(o.open().read() for o in ballads) # to make things easy we will gather all texts in one numpy array"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:02.808011Z","iopub.status.busy":"2023-10-13T02:15:02.805235Z","iopub.status.idle":"2023-10-13T02:15:02.815542Z","shell.execute_reply":"2023-10-13T02:15:02.814392Z","shell.execute_reply.started":"2023-10-13T02:15:02.807968Z"},"id":"Lu4ek-rIIn84","trusted":true},"outputs":[],"source":["def flatten(A):\n","    rt = []\n","    for i in A:\n","        if isinstance(i,list): rt.extend(flatten(i))\n","        else: rt.append(i)\n","    return rt\n","  \n","all_ballads = flatten(ballads)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:06.08493Z","iopub.status.busy":"2023-10-13T02:15:06.084615Z","iopub.status.idle":"2023-10-13T02:15:06.090255Z","shell.execute_reply":"2023-10-13T02:15:06.089169Z","shell.execute_reply.started":"2023-10-13T02:15:06.084901Z"},"id":"XHPQpvvbabmj","trusted":true},"outputs":[],"source":["class TransformersTokenizer(Transform):\n","    def __init__(self, tokenizer): self.tokenizer = tokenizer\n","    def encodes(self, x): \n","        toks = self.tokenizer.tokenize(x)\n","        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n","    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:07.437941Z","iopub.status.busy":"2023-10-13T02:15:07.437614Z","iopub.status.idle":"2023-10-13T02:15:07.445489Z","shell.execute_reply":"2023-10-13T02:15:07.444403Z","shell.execute_reply.started":"2023-10-13T02:15:07.437911Z"},"id":"KEdmTZR7NG5E","trusted":true},"outputs":[{"ename":"TypeError","evalue":"TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\annar\\OneDrive\\Desktop\\Visual Studio\\GitHub\\Projects2\\GenAI-and-LLMs\\poem-generation-with-transformers.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/annar/OneDrive/Desktop/Visual%20Studio/GitHub/Projects2/GenAI-and-LLMs/poem-generation-with-transformers.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m splits \u001b[39m=\u001b[39m [range_of(\u001b[39m70\u001b[39m), \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)] \u001b[39m# use a 70/30 split\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/annar/OneDrive/Desktop/Visual%20Studio/GitHub/Projects2/GenAI-and-LLMs/poem-generation-with-transformers.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tls \u001b[39m=\u001b[39m TfmdLists(all_ballads, TransformersTokenizer(tokenizer), splits\u001b[39m=\u001b[39;49msplits, dl_type\u001b[39m=\u001b[39;49mLMDataLoader)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[1;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mcls\u001b[39m): \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\core.py:368\u001b[0m, in \u001b[0;36mTfmdLists.__init__\u001b[1;34m(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m do_setup:\n\u001b[0;32m    367\u001b[0m     pv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSetting up \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, verbose)\n\u001b[1;32m--> 368\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(train_setup\u001b[39m=\u001b[39;49mtrain_setup)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\core.py:395\u001b[0m, in \u001b[0;36mTfmdLists.setup\u001b[1;34m(self, train_setup)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms\u001b[39m.\u001b[39mfs:\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mappend(\u001b[39mgetattr\u001b[39m(f, \u001b[39m'\u001b[39m\u001b[39minput_types\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mtype\u001b[39m(x)))\n\u001b[1;32m--> 395\u001b[0m         x \u001b[39m=\u001b[39m f(x)\n\u001b[0;32m    396\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mappend(\u001b[39mtype\u001b[39m(x))\n\u001b[0;32m    397\u001b[0m types \u001b[39m=\u001b[39m L(t \u001b[39mif\u001b[39;00m is_listy(t) \u001b[39melse\u001b[39;00m [t] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtypes)\u001b[39m.\u001b[39mconcat()\u001b[39m.\u001b[39munique()\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:81\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m---> 81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m'\u001b[39;49m\u001b[39mencodes\u001b[39;49m\u001b[39m'\u001b[39;49m, x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:91\u001b[0m, in \u001b[0;36mTransform._call\u001b[1;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, fn, x, split_idx\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m split_idx\u001b[39m!=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_idx \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_idx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, fn), x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:97\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[1;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m     96\u001b[0m     ret \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreturns(x) \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(f,\u001b[39m'\u001b[39m\u001b[39mreturns\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mreturn\u001b[39;00m retain_type(f(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), x, ret)\n\u001b[0;32m     98\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(f, x_, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m x_ \u001b[39min\u001b[39;00m x)\n\u001b[0;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m retain_type(res, x)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst)\n\u001b[0;32m    119\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","\u001b[1;32mc:\\Users\\annar\\OneDrive\\Desktop\\Visual Studio\\GitHub\\Projects2\\GenAI-and-LLMs\\poem-generation-with-transformers.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/annar/OneDrive/Desktop/Visual%20Studio/GitHub/Projects2/GenAI-and-LLMs/poem-generation-with-transformers.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencodes\u001b[39m(\u001b[39mself\u001b[39m, x): \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/annar/OneDrive/Desktop/Visual%20Studio/GitHub/Projects2/GenAI-and-LLMs/poem-generation-with-transformers.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     toks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mtokenize(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/annar/OneDrive/Desktop/Visual%20Studio/GitHub/Projects2/GenAI-and-LLMs/poem-generation-with-transformers.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mconvert_tokens_to_ids(toks))\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:337\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.tokenize\u001b[1;34m(self, text, pair, add_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, pair: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, add_special_tokens: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 337\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_plus(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mpair, add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mtokens()\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2781\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2771\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2772\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2773\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2774\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2778\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2779\u001b[0m )\n\u001b[1;32m-> 2781\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[0;32m   2782\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[0;32m   2783\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[0;32m   2784\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m   2785\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[0;32m   2786\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[0;32m   2787\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m   2788\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m   2789\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m   2790\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m   2791\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m   2792\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m   2793\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m   2794\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m   2795\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m   2796\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m   2797\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m   2798\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2799\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2800\u001b[0m )\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\tokenization_gpt2_fast.py:178\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m is_split_into_words \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mis_split_into_words\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    173\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_prefix_space \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    174\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou need to instantiate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with add_prefix_space=True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mto use it with pretokenized inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m )\n\u001b[1;32m--> 178\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_encode_plus(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:517\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode_plus\u001b[39m(\n\u001b[0;32m    496\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    497\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    515\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BatchEncoding:\n\u001b[0;32m    516\u001b[0m     batched_input \u001b[39m=\u001b[39m [(text, text_pair)] \u001b[39mif\u001b[39;00m text_pair \u001b[39melse\u001b[39;00m [text]\n\u001b[1;32m--> 517\u001b[0m     batched_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[0;32m    518\u001b[0m         batched_input,\n\u001b[0;32m    519\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    520\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    521\u001b[0m         padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[0;32m    522\u001b[0m         truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[0;32m    523\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m    524\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m    525\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m    526\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m    527\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m    528\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m    529\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m    530\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m    531\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m    532\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m    533\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    534\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    535\u001b[0m     )\n\u001b[0;32m    537\u001b[0m     \u001b[39m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    538\u001b[0m     \u001b[39m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    539\u001b[0m     \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m return_overflowing_tokens:\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\tokenization_gpt2_fast.py:168\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m is_split_into_words \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mis_split_into_words\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_prefix_space \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    164\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou need to instantiate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with add_prefix_space=True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    165\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mto use it with pretokenized inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m )\n\u001b[1;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_batch_encode_plus(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\annar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:445\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    438\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    439\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    442\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    443\u001b[0m )\n\u001b[1;32m--> 445\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[0;32m    446\u001b[0m     batch_text_or_text_pairs,\n\u001b[0;32m    447\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    448\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    449\u001b[0m )\n\u001b[0;32m    451\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    457\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[0;32m    458\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[0;32m    459\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[0;32m    469\u001b[0m ]\n","\u001b[1;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"]}],"source":["splits = [range_of(70), range(100)] # use a 70/30 split\n","tls = TfmdLists(all_ballads, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:15.814059Z","iopub.status.busy":"2023-10-13T02:15:15.813702Z","iopub.status.idle":"2023-10-13T02:15:20.51105Z","shell.execute_reply":"2023-10-13T02:15:20.510122Z","shell.execute_reply.started":"2023-10-13T02:15:15.814029Z"},"id":"0O-QWa9LN1IK","outputId":"7aecbf08-6d2e-4016-c2b5-d124d4e94329","trusted":true},"outputs":[],"source":["show_at(tls.train, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:32.912964Z","iopub.status.busy":"2023-10-13T02:15:32.912627Z","iopub.status.idle":"2023-10-13T02:15:39.445044Z","shell.execute_reply":"2023-10-13T02:15:39.444287Z","shell.execute_reply.started":"2023-10-13T02:15:32.912933Z"},"id":"Fv2mSN4LOHob","trusted":true},"outputs":[],"source":["bs,sl = 4,256\n","dls = tls.dataloaders(bs=bs, seq_len=sl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:43.485559Z","iopub.status.busy":"2023-10-13T02:15:43.485259Z","iopub.status.idle":"2023-10-13T02:15:43.610728Z","shell.execute_reply":"2023-10-13T02:15:43.609829Z","shell.execute_reply.started":"2023-10-13T02:15:43.485532Z"},"id":"xpbniW8mOT_g","outputId":"83aaae79-c35d-4192-920e-8e62869e01ec","trusted":true},"outputs":[],"source":["dls.show_batch(max_n=2)"]},{"cell_type":"markdown","metadata":{"id":"kMFnNw748QhY"},"source":["## Fine-tuning the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:49.271231Z","iopub.status.busy":"2023-10-13T02:15:49.270918Z","iopub.status.idle":"2023-10-13T02:15:49.275094Z","shell.execute_reply":"2023-10-13T02:15:49.274193Z","shell.execute_reply.started":"2023-10-13T02:15:49.271205Z"},"id":"jkJCLFncOcqV","trusted":true},"outputs":[],"source":["class DropOutput(Callback):\n","    def after_pred(self): self.learn.pred = self.pred[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:15:51.911967Z","iopub.status.busy":"2023-10-13T02:15:51.911635Z","iopub.status.idle":"2023-10-13T02:15:51.918041Z","shell.execute_reply":"2023-10-13T02:15:51.917007Z","shell.execute_reply.started":"2023-10-13T02:15:51.911935Z"},"id":"669gGIAuOeJ8","trusted":true},"outputs":[],"source":["learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:16:19.575784Z","iopub.status.busy":"2023-10-13T02:16:19.575487Z","iopub.status.idle":"2023-10-13T02:16:35.568428Z","shell.execute_reply":"2023-10-13T02:16:35.56752Z","shell.execute_reply.started":"2023-10-13T02:16:19.575755Z"},"id":"Z7ZPcyW8Oh0_","outputId":"ef19c779-2e66-41c4-cad8-e908400c1752","trusted":true},"outputs":[],"source":["learn.validate()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:16:41.988836Z","iopub.status.busy":"2023-10-13T02:16:41.988528Z","iopub.status.idle":"2023-10-13T02:17:14.710775Z","shell.execute_reply":"2023-10-13T02:17:14.709945Z","shell.execute_reply.started":"2023-10-13T02:16:41.988809Z"},"id":"ykYFFlCBOnqp","outputId":"27dae545-3669-4386-d399-76a8da0f964f","trusted":true},"outputs":[],"source":["learn.lr_find()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:17:26.630142Z","iopub.status.busy":"2023-10-13T02:17:26.629781Z","iopub.status.idle":"2023-10-13T02:18:04.239768Z","shell.execute_reply":"2023-10-13T02:18:04.238912Z","shell.execute_reply.started":"2023-10-13T02:17:26.630108Z"},"id":"PKySv6QiOvom","outputId":"ac533474-0ec1-4ddd-910c-c47e93098c96","trusted":true},"outputs":[],"source":["learn.fit_one_cycle(1, 1e-4)"]},{"cell_type":"markdown","metadata":{"id":"fdLpyolz8bV7"},"source":["## Poem Generation Example"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:18:15.739804Z","iopub.status.busy":"2023-10-13T02:18:15.739493Z","iopub.status.idle":"2023-10-13T02:18:15.746675Z","shell.execute_reply":"2023-10-13T02:18:15.745495Z","shell.execute_reply.started":"2023-10-13T02:18:15.739768Z"},"id":"D0zOA5wXPDEv","outputId":"27f4d6c1-e3af-4416-99cc-a071130a81c7","trusted":true},"outputs":[],"source":["prompt = 'love is ridiculous' # create an initial text prompt to start your generated text\n","prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","inp.shape"]},{"cell_type":"markdown","metadata":{"id":"_ONkBFg482US"},"source":["Adding the `num_beams` and `no_repeat_ngram_size` arguments make a huge difference. This can be explained [here](https://huggingface.co/blog/how-to-generate). Basically beam search reduces the risk of missing hidden high probability word sequences by keeping the most likely num_beams of hypotheses at each time step and eventually choosing the hypothesis that has the overall highest probability. Without beam search you will obtain a more greedy search. Beam search will always find an output sequence with higher probability than greedy search, but is not guaranteed to find the most likely output. Moreover, without the `no_repeat_ngram_size` you will likely obtain a repeated output. Thus we add a penalty that makes sure that no n-gram appears twice by manually setting the probability of next words that could create an already seen n-gram to 0."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:18:35.882744Z","iopub.status.busy":"2023-10-13T02:18:35.882433Z","iopub.status.idle":"2023-10-13T02:18:36.745433Z","shell.execute_reply":"2023-10-13T02:18:36.744486Z","shell.execute_reply.started":"2023-10-13T02:18:35.882715Z"},"id":"V39qs4aX4_3B","outputId":"31c2beac-22e8-4989-8826-fc50125b80e5","trusted":true},"outputs":[],"source":["preds = learn.model.generate(inp, max_length=60, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(preds[0].cpu().numpy(), skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:18:51.246072Z","iopub.status.busy":"2023-10-13T02:18:51.245715Z","iopub.status.idle":"2023-10-13T02:18:52.070553Z","shell.execute_reply":"2023-10-13T02:18:52.069651Z","shell.execute_reply.started":"2023-10-13T02:18:51.246042Z"},"id":"gEeoQrHrPb8c","outputId":"9d54d66a-654d-40c5-d87a-c9774e2c4ce0","trusted":true},"outputs":[],"source":["prompt = \"I don't know what I would do\"\n","prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","preds = learn.model.generate(inp, max_length=60, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(preds[0].cpu().numpy(), skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
